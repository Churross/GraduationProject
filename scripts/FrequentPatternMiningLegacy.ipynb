{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Frequent pattern mining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data and libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# import os\n",
    "# import scipy as sc\n",
    "# from scipy import stats\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# import datetime as dt\n",
    "import math\n",
    "import pickle\n",
    "# import scipy.cluster.hierarchy as shc\n",
    "from tqdm import tqdm\n",
    "# import time\n",
    "from spmf import Spmf\n",
    "import copy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File export suffix\n",
    "start_index = 0\n",
    "number_of_stays = 10\n",
    "display_matrix = True\n",
    "output_path = \"output/\"\n",
    "run_test_data = True\n",
    "output_folder = f\"stays-{number_of_stays}/\"\n",
    "# cluster_level = 0.725\n",
    "cluster_level = 0.76\n",
    "# output_folder = f\"stays-test-{number_of_stays}/\"\n",
    "\n",
    "# file_suffix = '_test_' + str(number_of_stays)\n",
    "file_suffix = '_' + str(number_of_stays)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store and load function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_as_pickle(data, file_name, path=output_path):\n",
    "    file = open(path + file_name, 'wb')\n",
    "    pickle.dump(data, file)\n",
    "    file.close()\n",
    "\n",
    "\n",
    "def get_pickle(file_name, path=output_path):\n",
    "    return pickle.load(open(path + file_name, 'rb'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphabet = list('abcdefghijklmnopqrstuvwyz')\n",
    "\n",
    "\n",
    "def number_to_character(index):\n",
    "    return alphabet[index]\n",
    "\n",
    "\n",
    "def character_to_number(character):\n",
    "    if character == 'x':\n",
    "        return \"-\"\n",
    "    else:\n",
    "        return alphabet.index(character)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = get_pickle('alignments' + file_suffix)\n",
    "# links = get_pickle('links' + file_suffix)\n",
    "# stays = get_pickle('stays' + file_suffix)\n",
    "# events = get_pickle('events' + file_suffix)\n",
    "# clusters = get_pickle('alignments' + file_suffix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frequent pattern mining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clustered_events(level):\n",
    "    keys = [float(cluster) for cluster in clusters.keys()]\n",
    "    keys.pop(0)\n",
    "\n",
    "    cluster_level = 0\n",
    "    level = float(level)\n",
    "\n",
    "    # TODO possibly change this to a binary search variant --> O(n) to O(log(n))\n",
    "    for clustered_level in keys:\n",
    "\n",
    "        if (level >= cluster_level and level < clustered_level):\n",
    "            break\n",
    "\n",
    "        else:\n",
    "            cluster_level = clustered_level\n",
    "\n",
    "    # return clusters[cluster_level]\n",
    "    return copy.deepcopy(clusters[cluster_level])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters.keys()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetch sequences at level\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# c = [seq['sequence'] for seq in get_clustered_events(0)]\n",
    "c = [seq['sequence'] for seq in get_clustered_events(cluster_level)]\n",
    "# c = c1.copy()\n",
    "# c = c1\n",
    "\n",
    "len(c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replace all events with character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def sequence_to_list_of_strings(c):\n",
    "#     transformed_sequences = copy.deepcopy(c)\n",
    "\n",
    "#     for c_index, cluster in enumerate(transformed_sequences):\n",
    "#         # print(cluster)\n",
    "#         for e_index, event in enumerate(cluster):\n",
    "#             # print(f\"event: {event}, instance: {isinstance(event, list)}\")\n",
    "\n",
    "#             if isinstance(event, list):\n",
    "#                 for index, e in enumerate(event):\n",
    "#                     # print(f\"e: {e}\")\n",
    "#                     if e == '-':\n",
    "#                         transformed_sequences[c_index][e_index][index] = 'x'\n",
    "#                         # c[c_index][e_index][index] = 100\n",
    "#                     else:\n",
    "#                         transformed_sequences[c_index][e_index][index] = number_to_character(\n",
    "#                             int(e))\n",
    "                        \n",
    "#                 s = transformed_sequences[c_index][e_index]\n",
    "#                 s.sort()\n",
    "#                 transformed_sequences[c_index][e_index] = \"\".join(s)\n",
    "#             # elif len(event) == 1:\n",
    "#             else:\n",
    "#                 # c[c_index][e_index] = int(event)\n",
    "#                 transformed_sequences[c_index][e_index] = number_to_character(\n",
    "#                     int(event))\n",
    "\n",
    "#         transformed_sequences[c_index] = \" \".join(\n",
    "#             transformed_sequences[c_index])\n",
    "    \n",
    "#     return transformed_sequences\n",
    "            \n",
    "\n",
    "# # print(c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sequence_to_list_of_strings(c):\n",
    "    transformed_sequences = copy.deepcopy(c)\n",
    "\n",
    "    for c_index, cluster in enumerate(transformed_sequences):\n",
    "        # print(cluster)\n",
    "        for e_index, event in enumerate(cluster):\n",
    "            # print(f\"event: {event}, instance: {isinstance(event, list)}\")\n",
    "\n",
    "            if isinstance(event, list):\n",
    "                for index, e in enumerate(event):\n",
    "                    # print(f\"e: {e}\")\n",
    "                    if e == '-':\n",
    "                        transformed_sequences[c_index][e_index][index] = 'x'\n",
    "                        # c[c_index][e_index][index] = 100\n",
    "                    else:\n",
    "                        transformed_sequences[c_index][e_index][index] = e\n",
    "\n",
    "                s = transformed_sequences[c_index][e_index]\n",
    "                s.sort()\n",
    "                transformed_sequences[c_index][e_index] = \"\".join(s)\n",
    "            # elif len(event) == 1:\n",
    "            else:\n",
    "                # c[c_index][e_index] = int(event)\n",
    "                transformed_sequences[c_index][e_index] = event\n",
    "\n",
    "        transformed_sequences[c_index] = \" \".join(\n",
    "            transformed_sequences[c_index])\n",
    "\n",
    "    return transformed_sequences\n",
    "\n",
    "\n",
    "# print(c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = sequence_to_list_of_strings(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VGEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_frequent_patterns(input=[], min_sup=0.1, max_gap='a', max_pat_length=\"\"):\n",
    "    spmf = Spmf(\"VGEN\", input_direct=input,\n",
    "                input_type=\"text\",\n",
    "                output_filename=\"output.txt\", spmf_bin_location_dir=\"/Users/youri/Downloads\",\n",
    "                arguments=[min_sup, max_pat_length, str(max_gap), True])\n",
    "    spmf.run()\n",
    "    # print(spmf.parse_output())\n",
    "    return spmf.to_pandas_dataframe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional: lengthen the dataset artificially"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# c1 = c.copy()\n",
    "# c1 = c\n",
    "# for i in range(5):\n",
    "#     c1 = c1 + c\n",
    "# print(f\"c: {len(c)}, c1: {len(c1)}\")\n",
    "for i in c:\n",
    "    print(f\"length seq: {len(i)}\")\n",
    "    \n",
    "# 17416\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in c:\n",
    "    print(f\"type: {type(i)}\")\n",
    "    print(f\"{i[0:50]}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mine patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LENGTH_THRESHOLD = 10000\n",
    "sequences = []\n",
    "sequence_to_split_pattern_lookup = []\n",
    "\n",
    "# for index, sequence in enumerate(c1):\n",
    "for index, sequence in enumerate(c):\n",
    "\n",
    "    if len(sequence) > LENGTH_THRESHOLD:\n",
    "        # print(f\"Index if: {index}\")\n",
    "        print(\n",
    "            f\"Sequence too long: {len(sequence)} - splitting: {math.ceil(len(sequence) / LENGTH_THRESHOLD)} x {LENGTH_THRESHOLD} = {math.ceil(len(sequence) / LENGTH_THRESHOLD) * LENGTH_THRESHOLD}\")\n",
    "        for i in range(0, math.ceil(len(sequence) / LENGTH_THRESHOLD)):\n",
    "            # print(f\"Part {i}: {i * LENGTH_THRESHOLD}-{(i + 1)* LENGTH_THRESHOLD - 1}\")\n",
    "            partial_sequence = sequence[i* LENGTH_THRESHOLD: (i + 1) * LENGTH_THRESHOLD - 1]\n",
    "            sequences.append(partial_sequence)\n",
    "        sequence_to_split_pattern_lookup.append( index + \n",
    "            math.ceil(len(sequence) / LENGTH_THRESHOLD) - 1)\n",
    "\n",
    "    else:\n",
    "        # print(f\"Index else: {index}\")\n",
    "        sequences.append(c[index])\n",
    "        sequence_to_split_pattern_lookup.append(index)\n",
    "        # sequences.append(c1[index])\n",
    "        \n",
    "print(\"-- Finished preparation --\")\n",
    "            \n",
    "        \n",
    "# sequences = []\n",
    "# c1 = [c for _ in range (0,10)]\n",
    "\n",
    "# for s_index, sequence in tqdm(enumerate(c1)):\n",
    "# sequences.append([[event] if isinstance(\n",
    "#     event, int) else event for event in sequence])\n",
    "\n",
    "# if len(sequence) > PATTERN_LENGTH:\n",
    "#     for i in range(0, len(sequence), PATTERN_LENGTH):\n",
    "#         chopped_sequences.append([[event] if isinstance(\n",
    "#             event, int) else event for event in sequence[i:i + PATTERN_LENGTH]])\n",
    "# else:\n",
    "#     chopped_sequences.append([[event] if isinstance(\n",
    "#         event, int) else event for event in sequence])\n",
    "\n",
    "# print('chopped up')\n",
    "\n",
    "\n",
    "# print(chopped_sequences)\n",
    "patterns = get_frequent_patterns(sequences, max_gap=1)\n",
    "# patterns = get_frequent_patterns(c1, max_gap=1)\n",
    "print(f\"\\n#patterns found: {len(patterns)}\")\n",
    "print(\"\\n-- Done --\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove patterns with length 0 or 1, sort on seq length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# patterns = patterns[patterns['pattern'].apply(lambda x: len(x) > 2)]\n",
    "patterns = patterns[patterns['pattern'].apply(lambda x: len(x) > 1)]\n",
    "patterns['encoding'] = range(300, len(patterns) + 300)\n",
    "patterns['seq_length'] = patterns.apply(lambda row: len(row.pattern), axis=1)\n",
    "# patterns = patterns.sort_values(by=['seq_length', 'sup'], ascending=False)\n",
    "# patterns = patterns.sort_values(by=['seq_length', 'sup'], ascending=[False, True])\n",
    "# patterns = patterns.sort_values(by=['sup', 'seq_length'], ascending=False)\n",
    "# patterns = patterns.sort_values(by=['sup', 'seq_length'], ascending=[False, True])\n",
    "# patterns = patterns.drop(columns=['seq_length'])\n",
    "print(len(patterns))\n",
    "patterns.head(n=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seq = [sequence['sequence'] for sequence in get_clustered_events(0)]\n",
    "# seq = [sequence['sequence']\n",
    "#        for sequence in get_clustered_events(cluster_level)]\n",
    "# seq = sequence_to_list_of_strings([sequence['sequence']\n",
    "#        for sequence in get_clustered_events(cluster_level)])\n",
    "seq = c\n",
    "# seq[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seq = [sequence['sequence'] for sequence in get_clustered_events(cluster_level)].copy()\n",
    "\n",
    "num_patterns_inserted = 0\n",
    "inserted_patterns = []\n",
    "s_adj = []\n",
    "\n",
    "for index, sequence in tqdm(enumerate(seq)):\n",
    "    s = \" \"+ (\" \".join(seq[index])) + \" \"\n",
    "    if s[0] != \" \":\n",
    "            s = s.ljust(len(s) + 1, \" \")\n",
    "    if s[-1] != \" \":\n",
    "            s = s.rjust(len(s) + 1, \" \")\n",
    "    s_adj.append(s)\n",
    "    for pattern in patterns.itertuples():\n",
    "        pat = \" \"+ \" \".join(pattern.pattern) + \" \"\n",
    "\n",
    "        if pat[0] != \" \":\n",
    "            pat = pat.ljust(len(pat) + 1, \" \")\n",
    "        if pat[-1] != \" \":\n",
    "            pat = pat.rjust(len(pat) + 1, \" \")\n",
    "            \n",
    "        s_old = s\n",
    "        s = s.replace(pat, str(pattern.encoding).center(len(str(pattern.encoding)) + 2, \" \"))\n",
    "    \n",
    "\n",
    "        if not s_old == s:\n",
    "            seq[index] = s\n",
    "            num_patterns_inserted += 1\n",
    "            inserted_patterns.append(pattern.encoding)\n",
    "\n",
    "print(f\"number of patterns inserted: {num_patterns_inserted}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# s_adj[1]\n",
    "# number of patterns inserted: 12197  --> original\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for pattern in inserted_patterns:\n",
    "#     print(f\"pattern: {pattern}-{patterns[patterns['encoding'] == pattern]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, sequence in tqdm(enumerate(seq)):\n",
    "    if isinstance(sequence, str):\n",
    "        seq[index] = sequence.split(\" \")\n",
    "        seq[index] = [value for value in seq[index] if value != \"\"]\n",
    "        # print(f\"Sequence: {index}\")\n",
    "        \n",
    "        \n",
    "        # print(seq[index])\n",
    "        # print(seq[index])\n",
    "        # seq[index] = [number_to_character(event) if isinstance(event, str) else event for event in seq[index]]\n",
    "        seq[index] = [str(event) if event.isdigit() else\n",
    "                      [str(character_to_number(e)) for e in event] if len(event) > 1 else str(character_to_number(event)) for event in seq[index]]\n",
    "        # seq[index] = [[int(event)] if event.isdigit() else\n",
    "        #                             [character_to_number(event)] for event in seq[index]]\n",
    "        \n",
    "        \n",
    "        # seq[index] = [[event] if event.isdigit() else \n",
    "        #               [str(character_to_number(event))] if len(\n",
    "        #     event) == 1 \n",
    "        #               else [str(character_to_number(e)) for e in \"\".join(event)] for event in seq[index]]\n",
    "        \n",
    "        # seq[index] = [number_to_character(event) if isinstance(event, str) else event for event in seq[index]]\n",
    "    \n",
    "    else: \n",
    "        # print('e')\n",
    "        # seq[index] = [int(event) if event.isdigit() ]\n",
    "        seq[index] = [[str(character_to_number(e)) for e in \"\".join(event)]\n",
    "         for event in seq[index]]\n",
    "\n",
    "\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 103243 --> 15\n",
    "# 4791 --> 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [int(event) if event.isdigit() else\n",
    "#  [character_to_number(e) for e in event] for event in seq[1][0: 10]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# s_test = [number_to_character(int(event)) if isinstance(event, str) else [number_to_character((e)) for e in event]for event in seq[1]]\n",
    "s_test = seq[1]\n",
    "s_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_clustered_events(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [['a', 'c', 'd'], ['a'], ['g', 3, 7, 5],['a', 2]]\n",
    "a.sort(key=len)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('backend-F9edf9D0')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8aa693308f7ebf26aebd877d93b16497504fa2934292b1fef41da166959c0225"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
