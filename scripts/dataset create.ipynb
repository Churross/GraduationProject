{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages and set global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import math\n",
    "import pickle\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clustering parameters\n",
    "number_of_stays = 1000\n",
    "start_index = 0\n",
    "display_matrix = False\n",
    "\n",
    "# File export suffix\n",
    "file_suffix = '_real_'+ str(number_of_stays)\n",
    "output_path = \"output/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_as_pickle(data, file_name, path=output_path):\n",
    "    file = open(path + file_name, 'wb')\n",
    "    pickle.dump(data, file)\n",
    "    file.close()\n",
    "\n",
    "\n",
    "def get_pickle(file_name, path=output_path):\n",
    "    return pickle.load(open(path + file_name, 'rb'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import MIMIC IV data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metadata = pd.read_csv(\"./dataset_files/mimic-cxr-2.0.0-metadata.csv\")\n",
    "icu = pd.read_csv('./dataset_files/icu_data_5000.csv')\n",
    "# icu = pd.read_csv('./dataset_files/first_6000_patients.csv', index_col=0)\n",
    "# icu_2000_2600 = pd.read_csv('./dataset_files/icu_data_2000-2600.csv')\n",
    "# icu_2600_3200 = pd.read_csv('./dataset_files/icu_data_2600-3200.csv')\n",
    "# icu_3200_3600 = pd.read_csv('./dataset_files/icu_data_3200-3600.csv')\n",
    "all_stays = pd.read_csv('./dataset_files/all_stays.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metadata.insert(0, 'metadata_id', range(0, 0 + len(metadata)))\n",
    "# metadata.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_stays = len(list(icu['hadm_id'].unique()))\n",
    "num_lables = len(list(icu['label'].unique()))\n",
    "print(f\"#stays: {num_stays}\\n#labels: {num_lables}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set intime for all_stays & metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_stays['charttime'] = pd.to_datetime(all_stays['intime'])\n",
    "# metadata['charttime'] = pd.to_datetime(metadata['StudyDate'], format='%Y%m%d')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess ICU dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = labels = list(icu['label'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freedman_diaconis(data):\n",
    "    \"\"\"\n",
    "    Use Freedman Diaconis rule to compute optimal histogram bin width. \n",
    "    ``returnas`` can be one of \"width\" or \"bins\", indicating whether\n",
    "    the bin width or number of bins should be returned respectively. \n",
    "\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data: np.ndarray\n",
    "        One-dimensional array.\n",
    "\n",
    "    returnas: {\"width\", \"bins\"}\n",
    "        If \"width\", return the estimated width for each histogram bin. \n",
    "        If \"bins\", return the number of bins suggested by rule.\n",
    "    \"\"\"\n",
    "    data = np.asarray(data, dtype=np.float_)\n",
    "    IQR = stats.iqr(data, rng=(25, 75), scale=\"raw\", nan_policy=\"omit\")\n",
    "    N = data.size\n",
    "    bw = max((2 * IQR) / np.power(N, 1/3), 1)\n",
    "\n",
    "    datmin, datmax = data.min(), data.max()\n",
    "    datrng = datmax - datmin\n",
    "    bins = int((datrng / bw) + 1)\n",
    "\n",
    "    return bw, bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binned_data(data, width, num_bins):\n",
    "  if np.isnan(width) or np.isnan(num_bins):\n",
    "    raise Exception(f'Width or num_bins is not a number')\n",
    "\n",
    "  binned_values = []\n",
    "\n",
    "  for value in data:\n",
    "    bin_index = math.floor(value/width)\n",
    "    binned_values.append(f'({bin_index * width}, {(bin_index+1) * width }]')\n",
    "\n",
    "  return binned_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "icu_binned = pd.DataFrame()\n",
    "blacklist = []\n",
    "\n",
    "for label in tqdm(labels):\n",
    "  values = icu[icu['label'] == label]\n",
    "  val_type = list(values['param_type'])\n",
    "\n",
    "  if (label in blacklist):\n",
    "    continue\n",
    "\n",
    "  if not ('Text' in val_type or 'Checkbox' in val_type):\n",
    "    IQR = stats.iqr(values['valuenum'], rng=(\n",
    "        25, 75), scale=\"raw\", nan_policy=\"omit\")\n",
    "\n",
    "    width, bins = freedman_diaconis(values['valuenum'])\n",
    "    values['value_categorical'] = values['label'] + \\\n",
    "        binned_data(values['valuenum'], width, bins)\n",
    "  elif('Checkbox' in val_type):\n",
    "    values['value_categorical'] = values['label'] + \\\n",
    "        binned_data(values['valuenum'], 1, 2)\n",
    "\n",
    "  icu_binned = pd.concat([icu_binned, values])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set ICU charttime to correct data type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "icu_binned['charttime'] = pd.to_datetime(icu_binned['charttime'])\n",
    "icu_binned.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set event for combining all dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "icu_binned['event'] = 'icu: ' +  icu_binned['label'].astype(str)\n",
    "# metadata['event'] = 'photo: ' + \\\n",
    "#     metadata['PerformedProcedureStepDescription'].astype(str)\n",
    "all_stays['event'] = 'transfer: ' + all_stays['eventtype']\n",
    "\n",
    "# data = pd.concat([all_stays, metadata, icu_binned])\n",
    "data = pd.concat([all_stays, icu_binned])\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "del icu_binned\n",
    "# del metadata\n",
    "del all_stays\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.sort_values(by=['hadm_id', 'charttime', 'event'], ascending=[False, False, True])\n",
    "# data_sort_1 = data[data['hadm_id'] == 28722652]\n",
    "# data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_sort_1.head(n=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.sort_values(by=['hadm_id','charttime', 'event'],\n",
    "                 ascending=[False,True, False])\n",
    "data.head(n=15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sort_2 = data[data['hadm_id'] == 28722652]\n",
    "data_sort_2.head(n=50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create encoded event "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['event_encoded'] = data['event'].astype('category')\n",
    "data['event_encoded'] = data['event_encoded'].cat.codes\n",
    "len(data.event_encoded.unique())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform event encodings to alphabet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphabet = list('abcdefghijklmnopqrstuvwyz')\n",
    "\n",
    "def number_to_character(index):\n",
    "    return alphabet[index]\n",
    "\n",
    "\n",
    "data['event_encoded'] = data['event_encoded'].apply(\n",
    "    lambda x: number_to_character(x))\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sort events on time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = data.sort_values(by=['charttime'])\n",
    "# data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add ID to events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.insert(0, 'event_id', range(0, 0 + len(data)))\n",
    "data.set_index('event_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save data as pickle and csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_as_pickle(data, 'data_complete_v4.1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(\"output/data_complete_v4.1.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create data export for distance matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = get_pickle('data_complete_v4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list(data['label'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_data = data[['event_id', 'hadm_id', 'event_encoded']]\n",
    "save_as_pickle(distance_data, 'distance_data_v4.1')\n",
    "distance_data.to_csv('output/distance_data_v4.1.csv')\n",
    "distance_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stays = list(distance_data['hadm_id'].unique())[\n",
    "    start_index: start_index + number_of_stays]\n",
    "\n",
    "lengths = []\n",
    "\n",
    "for y in tqdm(range(len(stays))):\n",
    "    sequence_y = distance_data[distance_data['hadm_id']\n",
    "                           == stays[y]]['event_encoded'].tolist()\n",
    "    lengths.append([stays[y], len(sequence_y)])\n",
    "\n",
    "length_data = pd.DataFrame(lengths, columns=['hadm_id', 'length'])\n",
    "length_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "length_data.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(n=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = data[data['hadm_id'] == 20001729]\n",
    "test.head(n=50)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('backend-F9edf9D0')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8aa693308f7ebf26aebd877d93b16497504fa2934292b1fef41da166959c0225"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
