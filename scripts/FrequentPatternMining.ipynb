{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Frequent pattern mining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data and libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# import os\n",
    "# import scipy as sc\n",
    "# from scipy import stats\n",
    "import numpy as np\n",
    "# import pandas as pd\n",
    "# import datetime as dt\n",
    "import math\n",
    "import pickle\n",
    "# import scipy.cluster.hierarchy as shc\n",
    "from tqdm import tqdm\n",
    "# import time\n",
    "from spmf import Spmf\n",
    "import copy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File export suffix\n",
    "start_index = 0\n",
    "number_of_stays = 100\n",
    "display_matrix = True\n",
    "output_path = \"output/\"\n",
    "run_test_data = True\n",
    "output_folder = f\"stays-{number_of_stays}/\"\n",
    "cluster_level = 0.725\n",
    "# cluster_level = 1\n",
    "# output_folder = f\"stays-test-{number_of_stays}/\"\n",
    "\n",
    "# file_suffix = '_test_' + str(number_of_stays)\n",
    "file_suffix = '_' + str(number_of_stays)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store and load function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_as_pickle(data, file_name, path=output_path):\n",
    "    file = open(path + file_name, 'wb')\n",
    "    pickle.dump(data, file)\n",
    "    file.close()\n",
    "\n",
    "\n",
    "def get_pickle(file_name, path=output_path):\n",
    "    return pickle.load(open(path + file_name, 'rb'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = get_pickle('alignments' + file_suffix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frequent pattern mining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clustered_events(level):\n",
    "    keys = [float(cluster) for cluster in clusters.keys()]\n",
    "    keys.pop(0)\n",
    "\n",
    "    cluster_level = 0\n",
    "    level = float(level)\n",
    "\n",
    "    # TODO possibly change this to a binary search variant --> O(n) to O(log(n))\n",
    "    for clustered_level in keys:\n",
    "\n",
    "        if (level >= cluster_level and level < clustered_level):\n",
    "            break\n",
    "\n",
    "        else:\n",
    "            cluster_level = clustered_level\n",
    "\n",
    "    # return clusters[cluster_level]\n",
    "    return copy.deepcopy(clusters[cluster_level])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters.keys()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetch sequences at level\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# c = [seq['sequence'] for seq in get_clustered_events(0)]\n",
    "c = [seq['sequence'] for seq in get_clustered_events(cluster_level)]\n",
    "# c = c1.copy()\n",
    "# c = c1\n",
    "\n",
    "len(c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replace all events with character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sequence_to_list_of_strings(c):\n",
    "    transformed_sequences = copy.deepcopy(c)\n",
    "\n",
    "    for c_index, cluster in enumerate(transformed_sequences):\n",
    "        # print(cluster)\n",
    "        for e_index, event in enumerate(cluster):\n",
    "            # print(f\"event: {event}, instance: {isinstance(event, list)}\")\n",
    "\n",
    "            if isinstance(event, list):\n",
    "                for index, e in enumerate(event):\n",
    "                    # print(f\"e: {e}\")\n",
    "                    if e == '-':\n",
    "                        transformed_sequences[c_index][e_index][index] = 'x'\n",
    "                        # c[c_index][e_index][index] = 100\n",
    "                    else:\n",
    "                        transformed_sequences[c_index][e_index][index] = e\n",
    "\n",
    "                s = transformed_sequences[c_index][e_index]\n",
    "                s.sort()\n",
    "                transformed_sequences[c_index][e_index] = \"\".join(s)\n",
    "            # elif len(event) == 1:\n",
    "            else:\n",
    "                # c[c_index][e_index] = int(event)\n",
    "                transformed_sequences[c_index][e_index] = event\n",
    "\n",
    "        transformed_sequences[c_index] = \" \".join(\n",
    "            transformed_sequences[c_index])\n",
    "\n",
    "    return transformed_sequences\n",
    "\n",
    "\n",
    "# print(c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# c = sequence_to_list_of_strings(c)\n",
    "seq = copy.deepcopy(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VGEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_frequent_patterns(input=[], min_sup=0.1, max_gap='1', max_pat_length=\"\"):\n",
    "    spmf = Spmf(\"VGEN\", input_direct=input,\n",
    "                input_type=\"text\",\n",
    "                output_filename=\"output.txt\", spmf_bin_location_dir=\"/Users/youri/Downloads\",\n",
    "                arguments=[min_sup, max_pat_length, str(max_gap), True])\n",
    "    spmf.run()\n",
    "    # print(spmf.parse_output())\n",
    "    return spmf.to_pandas_dataframe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional: lengthen the dataset artificially"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# c1 = c.copy()\n",
    "# c1 = c\n",
    "# for i in range(5):\n",
    "#     c1 = c1 + c\n",
    "# print(f\"c: {len(c)}, c1: {len(c1)}\")\n",
    "for i in c:\n",
    "    print(f\"length seq: {len(i)}\")\n",
    "    # print(i[0:10])\n",
    "    # print()\n",
    "    \n",
    "# 17416\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mine patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_gaps_and_to_string(c):\n",
    "    seqs = copy.deepcopy(c)\n",
    "    for s_index, sequence in enumerate(seqs):\n",
    "        for e_index, event in enumerate(sequence):\n",
    "            if isinstance(event, list):\n",
    "                s_temp = [e if e != \"-\" else 'x' for e in event]\n",
    "                s_temp.sort()\n",
    "                seqs[s_index][e_index] = \"\".join(s_temp)\n",
    "\n",
    "        seqs[s_index] = \" \".join(seqs[s_index])\n",
    "    return seqs\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEGMENT_SIZE = 4000\n",
    "FIRST_PERCENTILE = 2183\n",
    "FIRST_PERCENTILE = 8000\n",
    "segmented_sequences = []\n",
    "sequence_to_split_pattern_lookup = []\n",
    "sequences = copy.deepcopy(c)\n",
    "\n",
    "\n",
    "# TODO correct support\n",
    "\n",
    "# Split sequences to segmented sequences if larger than first percentile, else just add whole sequence\n",
    "for s_index, sequence in enumerate(sequences):\n",
    "    # print(type(sequence))\n",
    "    # print(sequence[0:100])\n",
    "    if len(sequence) > FIRST_PERCENTILE:\n",
    "        print(\n",
    "            f\"Sequence too long: {len(sequence)} - splitting: {math.ceil(len(sequence) / SEGMENT_SIZE)} x {SEGMENT_SIZE} = {math.ceil(len(sequence) / SEGMENT_SIZE) * SEGMENT_SIZE}\")\n",
    "        for i in range(0, math.ceil(len(sequence) / SEGMENT_SIZE)):\n",
    "            segmented_sequences.append(\n",
    "                sequence[i * SEGMENT_SIZE: (i + 1) * SEGMENT_SIZE - 1])\n",
    "        sequence_to_split_pattern_lookup.append(s_index +\n",
    "                                        math.ceil(len(sequence) / SEGMENT_SIZE) - 1)\n",
    "    else:\n",
    "        segmented_sequences.append(sequence)\n",
    "        sequence_to_split_pattern_lookup.append(s_index)\n",
    "        \n",
    "# Transform (segmented) list sequences to (segmented) string sequences\n",
    "sequences = replace_gaps_and_to_string(segmented_sequences)\n",
    "\n",
    "# for s in sequences:\n",
    "#     print(s[0:100])\n",
    "#     print()\n",
    "    \n",
    "print(\"-- Finished preparation --\")\n",
    "\n",
    "patterns = get_frequent_patterns(sequences, max_gap=1)\n",
    "# patterns = get_frequent_patterns(c1, max_gap=1)\n",
    "print(f\"\\n#patterns found: {len(patterns)}\")\n",
    "print(\"\\n-- Done --\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LENGTH_THRESHOLD = 20000\n",
    "# sequences = []\n",
    "# sequence_to_split_pattern_lookup = []\n",
    "\n",
    "# # for index, sequence in enumerate(c1):\n",
    "# for index, sequence in enumerate(c):\n",
    "\n",
    "#     if len(sequence) > LENGTH_THRESHOLD:\n",
    "#         # print(f\"Index if: {index}\")\n",
    "#         print(\n",
    "#             f\"Sequence too long: {len(sequence)} - splitting: {math.ceil(len(sequence) / LENGTH_THRESHOLD)} x {LENGTH_THRESHOLD} = {math.ceil(len(sequence) / LENGTH_THRESHOLD) * LENGTH_THRESHOLD}\")\n",
    "#         for i in range(0, math.ceil(len(sequence) / LENGTH_THRESHOLD)):\n",
    "#             # print(f\"Part {i}: {i * LENGTH_THRESHOLD}-{(i + 1)* LENGTH_THRESHOLD - 1}\")\n",
    "#             partial_sequence = sequence[i* LENGTH_THRESHOLD: (i + 1) * LENGTH_THRESHOLD - 1]\n",
    "#             sequences.append(partial_sequence)\n",
    "#         sequence_to_split_pattern_lookup.append( index + \n",
    "#             math.ceil(len(sequence) / LENGTH_THRESHOLD) - 1)\n",
    "\n",
    "#     else:\n",
    "#         # print(f\"Index else: {index}\")\n",
    "#         sequences.append(c[index])\n",
    "#         sequence_to_split_pattern_lookup.append(index)\n",
    "#         # sequences.append(c1[index])\n",
    "        \n",
    "# print(\"-- Finished preparation --\")\n",
    "            \n",
    "        \n",
    "# # sequences = []\n",
    "# # c1 = [c for _ in range (0,10)]\n",
    "\n",
    "# # for s_index, sequence in tqdm(enumerate(c1)):\n",
    "# # sequences.append([[event] if isinstance(\n",
    "# #     event, int) else event for event in sequence])\n",
    "\n",
    "# # if len(sequence) > PATTERN_LENGTH:\n",
    "# #     for i in range(0, len(sequence), PATTERN_LENGTH):\n",
    "# #         chopped_sequences.append([[event] if isinstance(\n",
    "# #             event, int) else event for event in sequence[i:i + PATTERN_LENGTH]])\n",
    "# # else:\n",
    "# #     chopped_sequences.append([[event] if isinstance(\n",
    "# #         event, int) else event for event in sequence])\n",
    "\n",
    "# # print('chopped up')\n",
    "\n",
    "\n",
    "# # print(chopped_sequences)\n",
    "# patterns = get_frequent_patterns(sequences, max_gap=1)\n",
    "# # patterns = get_frequent_patterns(c1, max_gap=1)\n",
    "# print(f\"\\n#patterns found: {len(patterns)}\")\n",
    "# print(\"\\n-- Done --\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove patterns with length 0 or 1, sort on seq length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# patterns = patterns[patterns['pattern'].apply(lambda x: len(x) > 2)]\n",
    "patterns = patterns[patterns['pattern'].apply(lambda x: len(x) > 1)]\n",
    "patterns['encoding'] = range(300, len(patterns) + 300)\n",
    "patterns['aggregated'] = patterns.apply(lambda row: any(len(i.strip()) > 1 for i in row.pattern), axis=1)\n",
    "patterns['seq_length'] = patterns.apply(lambda row: len(row.pattern), axis=1)\n",
    "patterns = patterns.sort_values(by=['seq_length', 'sup'], ascending=False)\n",
    "# patterns = patterns.sort_values(by=['aggregate'], ascending=True)\n",
    "# patterns = patterns.sort_values(by=['seq_length', 'sup'], ascending=[False, True])\n",
    "# patterns = patterns.sort_values(by=['sup', 'seq_length'], ascending=False)\n",
    "# patterns = patterns.sort_values(by=['sup', 'seq_length'], ascending=[False, True])\n",
    "# patterns = patterns.drop(columns=['seq_length'])\n",
    "print(len(patterns))\n",
    "patterns.head(n=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seq = [sequence['sequence'] for sequence in get_clustered_events(0)]\n",
    "# seq = [sequence['sequence']\n",
    "#        for sequence in get_clustered_events(cluster_level)]\n",
    "# seq = sequence_to_list_of_strings([sequence['sequence']\n",
    "#        for sequence in get_clustered_events(cluster_level)])\n",
    "# seq = copy.deepcopy(c)\n",
    "# seq = replace_gaps_to_string(c)\n",
    "# seq[0]\n",
    "# c[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insert patterns in sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seq = [sequence['sequence'] for sequence in get_clustered_events(cluster_level)].copy()\n",
    "# seq = copy.deepcopy(c)\n",
    "seq = replace_gaps_and_to_string(copy.deepcopy(c))\n",
    "\n",
    "num_patterns_inserted = 0\n",
    "inserted_patterns = []\n",
    "# s_adj = []\n",
    "# s_adj = \"\"\n",
    "# printing = True\n",
    "\n",
    "for index, sequence in tqdm(enumerate(seq)):\n",
    "    seq_inserted = 0\n",
    "    \n",
    "    s = \" \" + sequence  + \" \"\n",
    "    if s[0] != \" \":\n",
    "        s = s.ljust(len(s) + 1, \" \")\n",
    "    if s[-1] != \" \":\n",
    "        s = s.rjust(len(s) + 1, \" \")\n",
    "    # s_adj.append(s)\n",
    "    # s_adj = copy.deepcopy(s)\n",
    "    # print(s_adj)\n",
    "    for pattern in patterns.itertuples():\n",
    "        pat = \" \" + \" \".join(pattern.pattern) + \" \"\n",
    "\n",
    "        if pat[0] != \" \":\n",
    "            pat = pat.ljust(len(pat) + 1, \" \")\n",
    "        if pat[-1] != \" \":\n",
    "            pat = pat.rjust(len(pat) + 1, \" \")\n",
    "        \n",
    "        # if printing:\n",
    "        #     print(f\"pat: -{pat}-\")\n",
    "        #     print(f\"pat: {pattern.encoding}\")\n",
    "        #     printing = False\n",
    "\n",
    "        s_old = s\n",
    "        # print(s)\n",
    "        s = s.replace(pat, str(pattern.encoding).center(\n",
    "            len(str(pattern.encoding)) + 2, \" \"))\n",
    "\n",
    "        if not s_old == s:\n",
    "            seq[index] = s\n",
    "            # print(f\"pat: {pat}, {pattern.encoding}\")\n",
    "            # print(s[0:200])\n",
    "            seq_inserted += 1\n",
    "            num_patterns_inserted += 1\n",
    "            inserted_patterns.append(pattern.encoding)\n",
    "    \n",
    "    # print(f\"inserted in sequence {index}: {seq_inserted}\")\n",
    "\n",
    "print(f\"number of patterns inserted: {num_patterns_inserted}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Format string to original representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for index, sequence in tqdm(enumerate(seq)):\n",
    "    # print(type(sequence))\n",
    "    if isinstance(sequence, str):\n",
    "        seq[index] = sequence.strip().split(\" \")\n",
    "       \n",
    "        \n",
    "        for e_index, event in enumerate(seq[index]):\n",
    "            if event.isdigit():\n",
    "                if patterns.iloc[np.where(patterns.encoding.values == int(event))].aggregated.values[0]:\n",
    "                    seq[index][e_index] = [int(event)]\n",
    "                else:\n",
    "                    seq[index][e_index] = int(event)\n",
    "            else:\n",
    "                if len(event) > 1:\n",
    "                    seq[index][e_index] = [e for e in event]\n",
    "                else:\n",
    "                    seq[index][e_index] = event\n",
    "    else: \n",
    "        print(f'[ERROR] detected other type: {type(sequence)}')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "print(\"[INFO] Writing to file...\")\n",
    "#  Write to file\n",
    "fileName = \"sequences-\" + str(100) + \"-\" + str(cluster_level) + \".csv\"\n",
    "with open(fileName, \"w\", newline='') as f:\n",
    "    wr = csv.writer(f)\n",
    "    wr.writerows(seq)\n",
    "\n",
    "print(\"[INFO] Done.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patterns.to_csv(f'patterns-{number_of_stays}-level-{cluster_level}.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_sequences = [seq['sequence']\n",
    "                          for seq in get_clustered_events(cluster_level)]\n",
    "\n",
    "for i in range(len(original_sequences)):\n",
    "    len_o = len(original_sequences[i])\n",
    "    len_n = len(seq[i])\n",
    "    print(f\"Original length: {len_o}\")\n",
    "    print(f\"New length: {len_n}\")\n",
    "    print(f\"Reduction: {(len_n - len_o)/ len_o * 100} \")\n",
    "    print(\"----\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('backend-F9edf9D0')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8aa693308f7ebf26aebd877d93b16497504fa2934292b1fef41da166959c0225"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
